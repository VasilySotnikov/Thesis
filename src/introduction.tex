\begin{quote}
$\Gamma N \Omega \Theta I$ $\Sigma E A \Upsilon T
O N$ - Gnothi Seauton - know thyself\\
Inscription at the temple of Apollo in Delphi, Greece
(1\textsuperscript{st} millennium B.C.)
\end{quote}



The most successful theory to describe fundamental particles and their interactions is the
Standard Model of particle physics (SM). The SM is widely considered a low-energy approximation to some underlying and
more fundamental description of nature. In particular due to its shortcoming
of not to include both the gravitational force and the indirect evidence of new types of matter referred to as dark matter in its unified description
of particle interactions. Currently, the SM undergoes stringent testing at the Large Hadron Collider (LHC) at CERN. With its current center-of-mass energy of $13$ TeV, both measurements
of properties of known particles as well as searches for yet to
discover new physics are conducted at an unprecedented
energy regime. 

As of today, no apparent statistically significant deviations from SM predictions - and thus no physics beyond the SM (BSM) - have been detected at the LHC. Additionally many
properties of the newly discovered Higgs boson have been established. These early results narrow
the future exploration
for new particle phenomena. An
important input for the
understanding of
expected phenomena as well as searches for new physics are
reliable theory predictions. In particular, since new
phenomena will reveal themselves through subtle effects and small
deviations from SM predictions for complex processes. This necessitates ever more precise
predictions for multi-particle observables within the SM in order to probe it at a
deeper level.



At the heart of theoretical predictions for particle collisions at
the LHC are fixed-order calculations in perturbative quantum field theory. Currently required theory predictions include quantum corrections in quantum chromodynamics (QCD) and electroweak theory (EW). State-of-the-art are higher-order
corrections at next-to-next-to-leading order (NNLO)
accuracy in QCD for processes with up to two
particles or objects in the final state, EW next-to-leading order
(NLO) corrections as well as
NLO QCD corrections for complex final states with many particles. In
this dissertation we focus on the problem of
computing NLO QCD corrections to processes with massive quarks in the
loop and with many particles in the final state. Notably,
we consider weak-gauge-boson production in association with
many heavy and light jet. This process class is abundantly produced at the LHC and thus constitutes a suitable testing ground for theory predictions and measurements. Furthermore it is an irreducible background to many important signatures and needs to be understood precisely.
% Furthermore, these high-multiplicity processes appear as irreducible backgrounds to both measurements of SM parameters as well as new-physics searches.



Calculations in perturbation theory at a fixed-order of the
respective coupling are valuable from a theoretical point of view: Firstly, they are based on first
principles and thus directly link measurements to quantum field theory. Furthermore, a categorization of predictions by the
included order is possible with an
assumed order-by-order improvement of the accuracy. And finally, they are
amenable to automation, which allows for the computation of higher-order
correction to increasingly complex processes. In
general, fixed-order predictions have a parametric dependence on the input of physical
quantities such as couplings, parton-distribution
functions (PDFs) and masses of the involved particles. The theoretical
uncertainty associated to fixed-order predictions is then an accumulation of the
uncertainties associated to the input parameters listed above as well
as the uncertainties associated to missing higher-order effects due to the truncation of the perturbative expansion. Since
the latter are not known in general and often constitute the leading
source of uncertainty, the estimation of theoretical uncertainties of
fixed-order calculations is
a difficult problem. 


The truncation of the perturbative series at a finite
order leads to a dependence of fixed-order predictions on the unphysical renormalization
and factorization scale $\mu$. This residual dependence would not be present in a full prediction and is compensated in a complete perturbation series by higher-order terms. As a consequence, the dependence on $\mu$ can be used as an estimate of the magnitude of missing higher-order effects. The renormalization scale, which is introduced in dimensional regularization to retain the correct mass dimension of the appearing integral functions, is also used as the scale at which the input parameters are specified. In the computation of fixed-order cross-sections, the question of which scale to use is important and there exist different
proposals how to deal with it.\footnote{See for example the contributions to the recent
  workshop ``Taming Unphysical Scales for Physical Predictions'',
  30.-31.03.2017, Cambridge.} One widely used approach for dynamical scale setting is to take an accelerated convergence of the perturbative expansion for
particular observables as the guiding principle \cite{Czakon:2016dgf} of whether or
not a scale choice is sensible. Typically, a functional form that reflects the hardness of the process under consideration is chosen. For example, the dynamical scale choice $\mu_0=\HTpartonicp/2$ (defined in Sec.~\ref{sec:kin}), the total partonic energy in the transverse plane, has
proven to be a sensible choice for the process class of weak-vector-boson production in association with many light jets at the LHC. It tends to reduce the shape changes and global size of quantum corrections
when going from leading order (LO) to NLO (see for
example~\cite{BH:W5j,BH:Z4j,BH:Wratios}). The above approach has been successfully applied to many NLO
QCD predictions and is
convenient from a practical point of view. However, it suffers from a
missing underlying physical explanation and its coarse-grained approach uses no detailed information about kinematics and parton content
of each event to determine the corresponding scale $\mu$. The more intuitive \MINLO{} method~\cite{MINLO} accommodates kinematical information of the underlying Born process by building the most likely branching history with a jet clustering algorithm, as in the CKKW procedure~\cite{CKKW}. The strong couplings are then evaluated at the corresponding transverse momentum at each branching and no-branching probabilities in the form of Sudakov form factors are assigned. The \MINLO{} method ensures NLO accuracy of the procedure. Other approaches are based on the idea of restoring the
conformal or scale-invariance symmetry in observables directly, like the Principle of Maximum
Conformality \cite{Brodsky:2011ta,Mojaza:2012mf}. In this work we make
for the first time an in depth study of the \MINLO{} procedure for
processes with more than four jets in the final state and compare to results obtained with $\HTpartonicp/2$ for validation.


The current physics runs at the LHC
explore a wide range of scales, from tens of GeVs to the multi-TeV
regime. In particular this large hierarchy of scales makes LO QCD predictions
unreliable, as they tend to be very sensitive to the unphysical renormalization and
factorization scales. Furthermore, LO predictions often miss important
initial-state partonic configurations. The inclusion of consecutive
orders in perturbation theory reduces the dependence on unphysical
scales and NLO QCD predictions allow for a first reliable extrapolation into tails of distribtutions.\footnote{Processes with missing partonic channels and
  large accessible phase space at NLO are
  an exception to this and require NNLO calculations, as pointed out
  for example in~\cite{Rubin:2010xp}.} The NLO QCD corrections to $W$+jets production have a long history \cite{Giele:1993dj} and correction to $W+2$ jets \cite{Bern:1997sc}, $W+3$ jets \cite{BH:W3jDistributions}, $W+4$ jets \cite{BH:W4j} and $W+5$ jets \cite{BH:W5j} are known. Also predictions for $W$ production in association with heavy quarks are known with NLO QCD results for \Wbb{} production \cite{FebresCordero:2006sj} and $Wb\bar{b}+1$-jet production \cite{Luisoni:2015mpa} being available. Likewise the NLO QCD corrections to $Z+1$ jet \cite{Giele:1993dj}, $Z+2$ jets \cite{Campbell:2002tg}, $Z+3$ jets \cite{Berger:2010vm} and $Z+4$ jets \cite{BH:Z4j} production have been computed. We show in this work the first NLO QCD calculation of a
process with a $W$ boson, two heavy jets as well as two and three light jets in the final state and demonstrate how the quantum corrections
considerably stabilize the theoretical predictions. Furthermore, we perform a dedicated study of $W^\pm$ production in association with five light jets and $Z$ in
association with four light jets. Currently, there is also remarkable progress on NNLO calculations, with phenomenological
prediction for $2\rightarrow 2$ processes such as vector-boson
production with a single jet
\cite{Boughezal:2015dva,Boughezal:2015ded,Gehrmann-DeRidder:2016zml} being
available. 






In the following, we elaborate in more detail on the
difficulty of computing NLO QCD corrections to high-multiplicity processes with
massive quarks in the loop and outline the approach that we have used
and developed in this
work. Furthermore, we highlight the two phenomenological studies on weak-gauge-boson production in association with heavy and light
jets that we have performed.



\subsubsection{The Challenge of Computing NLO QCD Corrections to High-Multiplicity Processes with Massive Quarks}
\label{sec:chall-high-mult}

We provide for the first time NLO QCD predictions for the production of \Wbb~in association with two and
three light jets, as presented in~\cite{wbbpaper}. The high-multiplicity of these processes with up to eight particles in
the loop as well as the additional scale introduced by the
bottom quark mass makes the computation of NLO QCD predictions for
these processes a challenging
task.

 We use the unitarity method~\cite{Bern:1994zx,Bern:1994cg,
Britto:2004nc} and its extension to massive
particles~\cite{Bern:1995db} which has been applied by a number of groups for analytic as well as numerical computations
of massive amplitudes
\cite{Badger:2010mg,Badger:2011yu,Melnikov:2009dn}. To this end, we implement the numerical
unitarity
approach~\cite{Ossola:2006us,Ellis:2007br,Giele:2008ve,Berger:2008sj} and
its extension to massive quarks~\cite{Ellis:2008ir} for the
computation of our NLO QCD predictions. Unitarity methods obtain the integrands of one-loop amplitudes directly from on-shell
tree amplitudes, thus avoiding an explicit reduction of tensor and higher-rank
integrals. Our approach shares common features with the Ossola, Papadopoulos and Pittau (OPP) reduction
method~\cite{Ossola:2006us}. Using suitable
loop-momentum parameterizations allows to set $n$ loop propagators
on-shell, and the amplitude factorizes into a product
of $n$ tree amplitudes. We use Berends-Giele (BG) off-shell
recurrence relations~\cite{Berends:1987me} to compute the required
tree amplitudes numerically, which allows for an
efficient and flexible tree generation for both complex and $D$-dimensional
momenta. 


The computation of single cuts
for the extraction of tadpole coefficients
and double cuts for the extraction of coefficients of bubbles with a single
on-shell leg require a special treatment, since explicit divergences
associated to both tadpole Feynman diagrams and self-energy insertions on external legs
are encountered in their computation. We follow the prescription for
the treatment of double cuts of
Ref.~\cite{Ellis:2008ir} which also applies to single cuts, that is we remove the divergent contributions by adjusting
the tree-diagram generation. This procedure is connected to mass renormalization in order to produce gauge-invariant results. Alternative approaches have been presented in
Ref.~\cite{Britto:2011cr} and, recently, in Ref.~\cite{Badger:2017gta}.


We use the four-dimensional helicity
(FDH)~\cite{Bern:1991aq,Bern:2002zk} variant of dimensional
regularization in our calculation of $D$-dimensional
unitarity~\cite{Giele:2008ve}. We developed a prescription to map the higher-dimensional
Dirac algebra into four-dimensional objects \cite{angerds} to
numerically evaluate
the required cuts efficiently. More precisely, whenever
possible we reduce the $D_s$-dimensional algebra and states to four dimensions.
The known decomposition of the $D_s=6$ dimensional gluon amplitude to a $D_s=5$
amplitude plus a scalar contribution~\cite{Bern:1994cg} is in close
analogy to our approach. Our prescription allows to avoid an overhead of
numerical computations in higher-dimensional representations of the
Dirac algebra, and can
be equivalently derived from the four-dimensional
(re-)formulation (FDF) of FDH~\cite{Fazio:2014xea} with some adaptions. This is done with
a crucial modification based on imposing higher-dimensional Dirac
traces for the computation of the loop amplitudes. The latter proved
fundamental for generic application which can include multiple massive
fermion lines. We have implemented the described methods into an upgraded version of the \BlackHat{}
library~\cite{Berger:2008sj}, which can now compute one-loop matrix
elements with multiple massive quarks. A future extension of the presented
methods could come by an
application in the recently developed numerical unitarity method for two-loop calculations
\cite{Ita2016,Abreu:2017idw}, which was applied for the computation of four-
\cite{Abreu:2017xsl} and five-gluon amplitudes \cite{Abreu:2017hqn}.

\subsubsection{Phenomenology of Weak-Vector-Boson Production in
  Association with Heavy and Light Jets}
\label{sec:phen-pred-wbb}



The experimental signatures of vector-boson production in association
with many heavy and light jets contain charged leptons, missing
transverse energy from undetected neutrinos and multiple heavy and light jets. The possibility of identifying leptons and thereby
distinguishing the events from QCD multijet background is important from the experimental point of view. The above mentioned processes appear as irreducible backgrounds to many searches for new physics ongoing at the LHC Run-II. The decay of $Z\rightarrow
\nu\bar{\nu}$ in association with jets for example has a signature
that appears at the end of a decay cascade of typical new-physics
scenarios. For example, it is an irreducible background to searches for the hypothetical production of
supersymmetric pairs of squarks and gluinos that decay into jets and
undetected lightest supersymmetric
particles~\cite{Collaboration:2011ida,Aad:2011ib,Chatrchyan:2014lfa,Aad:2014wea,Khachatryan:2016kdk,Aaboud:2017vwy}. Also the signature of \Wbb~production often appears in the
decay chains of heavy massive particles predicted in BSM theories, e.g.\ those for the superpartners of the
third generation quarks, sbottom and stop \cite{ATLASCollaboration2015,ATLAS13sbottom16,ATLAS13sbottom17}. During the $7$ and $8$
  TeV runs of the LHC, the ATLAS \cite{Aad:2012en,Aad:2011qv,Aad:2010ab,Aad:2011xn,ATLASRatioWZ14,Aad:2014qxa,ATLAS7Zjets13,ATLAS:ratio2017}
and CMS
\cite{Khachatryan:2014uva,Chatrchyan:2011ne,Chatrchyan:2013tna,CMS7Zjets15,Khachatryan:2016fue,Khachatryan:2015ira,CMS8Zjets16}
experiments have scrutinized vector-boson production in association
with light jets. The first measurements at an
energy of $13$ TeV by both
collaborations \cite{Aaboud:2017hbk,Sirunyan:2017wgx} continue to illustrate
to which extend theoretical predictions, by both calculations specific
to the process class as well as general Monte Carlo event generators, describe
the experimental data. The recent experimental
analysis for $Z/\gamma^*$+jets production \cite{Aaboud:2017hbk}
compares, amongst others, to our predictions \cite{Anger:2017nkq} presented in Chapter
\ref{chap:vjet_result}. 

The inclusion of $b$ jets in the experimental signature is important to
study since key processes of the SM and of BSM physics involve heavy quarks. Hence, this process is irreducible
background to important measurements and searches such as the associated Higgs production in the $HW$ channel, with the consequent decay of
the Higgs boson into a $b\bar{b}$ pair. The $HW$ production
channel signal strength is well in accordance with the SM expectation
\cite{ATLAS2015Higgs} but only recently evidence for the
decay of the Higgs boson to a $b$-quark pair was found
\cite{ATLAS:hbb2017}. Processes with heavy
flavor content are harder to measure and to predict
theoretically. Among the experimental challenges is the correct
identification and modeling of bottom quarks \cite{ATLASbtag}. Experimental measurements of \Wbb~production have been performed by
both ATLAS \cite{Aad:2013vka} and CMS \cite{CMS:2016bb,Chatrchyan:2013uza},
providing a variety of results, both with and without additional light
jets.

In this dissertation, we present two phenomenological studies for the
above process class, namely for \Wbb~production in
association with light jets and for $V$ ($V=W^\pm,Z$)
production in association with light jets.


We present NLO QCD predictions for \Wbb~production in association with up to
three light jets at the LHC~\cite{wbbpaper}. In order to do so, we use our new version of
the \BlackHat{} library in combination with the \SHERPA{} Monte Carlo
program~\cite{Sherpa}. We compute in the four-flavor number scheme (4FNS), that is we consistently treat bottom quarks as massive particles and consider all mass effects in closed-fermion-loop contributions. Previously, NLO QCD predictions that
retain the
full mass dependence were computed for \Wbb{}
production~\mbox{\cite{FebresCordero:2006sj,Cordero:2009kv}} and
recently for $Wb\bar{b}+1$-jet production~\cite{Luisoni:2015mpa}. The NLO QCD correction to \Wbb{} production are
large~\cite{Ellis:1998fv,FebresCordero:2006sj,Cordero:2009kv} due to
the opening of a gluon-initiated channel in real contributions and the release of a LO
kinematical constraint which fixes the $p_T$ of the $W$ boson to that of the
$b\bar b$ system. In order to get reliable theoretical predictions for this process in
spite of giant $K$-factors~\cite{Rubin:2010xp}, we employ our set of
light-jet high-multiplicity NLO QCD results to compute observables
based on exclusive sums~\cite{ESums}. Comparison to LHC
data for $W+1$-jet
production \cite{Aad:2014qxa,ATLAS:ratio2017} shows that exclusive-sum
observables improve perturbative predictions, since they can contain
large contributions that first appear at NNLO. Since \Wbb~production is an
irreducible background to $H(\rightarrow b{\bar b})W$
production, we focus on observables associated to it and study the $p_T^{b\bar b}$, $p_T^W$, and
$M_{b\bar b}$ exclusive-sum distributions.



We have made a dedicated study of weak-vector-boson production in
association with light jets at the $\sqrt{13}$ TeV LHC \cite{Anger:2017nkq}. We provide predictions for $W+n$-jet and $Z+m$-jet production in
association with $n\leq 5$ and \mbox{$m\leq 4$} light jets for which
we use the \BlackHat{} library~\cite{BlackHatI}
in combination with \SHERPA{} \cite{Sherpa}, and extract a set of
\ntuple{} files \cite{BH:Ntuples} for future usage. We study in detail the comparison of fixed-order scales based on the total partonic transverse energy and
different variants of the more physically motivated \MINLO{} method~\cite{MINLO}. We thereby estimate
the theoretical uncertainties associated
to our predictions that are related to scale sensitivity. In addition,
we perform conventional scale variations by constant factors around the central
scales as a proxy for missing higher-order terms. With our
analysis we extend the comparison of fixed-order scales with the
\MINLO{} method to NLO QCD results with four or five light jets in the final
state. Furthermore, we explore uncertainties of our high-multiplicity
results associated to the choice of PDFs.


\section{Structure of this Thesis}
\label{se:structure}
In Chapter \ref{chap:sm}, we introduce the SM and briefly
describe hadronic collisions. The first part of the thesis consists
of Chapters \ref{chap:vme2}\nobreakdash--\ref{chap:renorm} and is
devoted to a description of the methods and
tools that we used and developed in order to obtain the required matrix elements for
\Wbbn~production, as implemented in the new version of the \BlackHat~library. In Chapter \ref{chap:vme2} we describe the
handling of the color degrees of freedom and in Chapter
\ref{chap:num_quark} we present the method of numerical
unitarity for massive quarks. Chapter \ref{chap:fdf} is devoted
to the study of the dimensional dependence of one-loop helicity
amplitudes, from which we derive an efficient prescription to compute
higher-dimensional unitarity cuts. In Chapter
  \ref{chap:renorm}, we give details for the required renormalization
  procedure of our matrix-elements.


In the second part of this thesis, we present a phenomenological study
of \Wbbn~production. In Chapter \ref{chap:wbb_intro}, we give an
introduction and describe our basic setup. Chapter
\ref{chap:wbb_validation} is devoted to a thorough validation of the
new matrix elements and we provide checks of the numerical stability
as well as comparisons with other automated codes. In Chapter
\ref{chap:wbb_results}, we make use of the new matrix elements and
provide NLO QCD predictions for \Wbbn~production. We study both total
rates and differential distributions as well as observables based on
exclusive sums of relevance for $H(\rightarrow b\bar{b})W$ studies at the LHC.

The final part of the thesis, consisting of Chapters
  \ref{chap:vjet_basic} and Chapter \ref{chap:vjet_result}, is
devoted to a phenomenological study of \ew~gauge boson ($V=Z,W^\pm$) production
in association with up to four ($Z$) or five ($W^\pm$) light jets. We
thereby extend existing predictions to the higher energy of $13$ TeV
attained during Run-II of the LHC. We provide predictions using two
different functional forms of dynamical scales. In particular, we
study for the first time the application of the \MINLO{} procedure to
high-multiplicity processes and find that predictions obtained with
both the \MINLO{} method and $\HTpartonicp/2$~agree reasonably well. 

We conclude and
give an outlook in Chapter \ref{chap:so}.

Understanding the fundamental principles of Nature has been one of the most
longstanding and remarkable adventures of the human civilization.
Our perception of Nature has undoubtedly advanced to an incredible height,
nevertheless, it still seems to be in it's infancy regarding the most
fundamental questions. And if there is ever an end to this adventure, it does
not appear to come today.
It is the foremost objective of this thesis, to
contribute a tiny speck to our cumulative knowledge,
in a hope that together these contributions add up to eventually make a bigger step forward.

In the beginning of the 21\textsuperscript{st} century, our best description of all combined experimental data fits into the picture of elementary particles and their local interactions.
Elementary particles, in turn, are excitations of the underlying quantum fields, which occupy the entirety of the background four-dimensional space-time.
\emph{Quantum field theory} (QFT) is the formal framework that allows to formulate this picture quantitatively.
QFT provides solid ground to a very intuitive idea,
that, to probe the most elementary structures, one needs to observe the properties of very high-energetic interactions of particles.
The shorter the length scale of phenomena in interest, the higher the energy required.\footnote{
  It is clear that this picture must, in fact, break down at most around the energy density sufficient to produce black holes.
  This exactly corresponds to the energy scale, where the unknown effects of quantum gravity are expected to become important.
}

The Standard Model of particle physics (SM) is the most successful QFT to date.
It has been scrutinized experimentally over and over again in the last decades, and the
last missing piece required for its self-consistency, the Higgs particle, has been discovered recently by the most
powerful laboratory for studying  the high-energy collisions to date, the \emph{Large Hadron Collider} (LHC) at CERN.
We therefore, for the first time in the history, have a model which can be, at least in principle, extrapolated to the energy scales many orders of magnitude higher than
any characteristic scales of the model itself.
On the other hand, it is also clear, that the SM is not a complete theory.
The SM fails to address a wide variety of both theoretical concerns and (mostly astrophysical) experimental observations, such as
\begin{itemize}[nosep,topsep=-1.6ex]
  \item an ultra-violet completion of gravity,
  \item an origin of generations and the mass hierarchy in the fermion sector,
  \item baryon asymmetry in the observable universe, 
  \item an apparent existence of dark matter,
  \item[]  $\cdot\quad\cdot\quad\cdot$ %\qquad $\vdots{}$\qquad $\vdots{}$\qquad $\vdots{}$\qquad $\vdots{}$\qquad $\vdots{}$\qquad $\vdots{}$\qquad $\vdots{}$\qquad $\vdots{}$\qquad $\vdots{}$
\end{itemize}
The SM is, thus, understood to be a low-energy approximation to a more fundamental theory.
It is, therefore, of central importance to exactly determine the domain of its validity,
and establish stringent constraints on potential beyond-the-standard-model extensions.

A key ingredient in this quest is the ability to interpret the measurements extracted from the collider experiments, such as the LHC, as precisely as possible.
These have to be compared to precise predictions of the SM and possibly, new physics models.
In the absence of such theory predictions, new physics may remain undetected, or the SM backgrounds may be falsely identified as such.

The discovery potential of hadron colliders is limited by both experimental and theoretical uncertainties.
While the experimental uncertainties for a wide range of observables at the LHC are, or expected to be in the near future, of the order of few percents,
theoretical predictions are in general yet to match this unprecedented level of precision.
The theoretical description of hadron collisions requires contributions from diverse areas of research.
Broadly speaking, they can be classified into the long-distance (or low-energy) effects from 
the strong-coupling regime of the quantum chromo-dynamics (QCD), the short-distance hard scattering, and
the cross-over from one to another.
Each of them reaches into a particular corner of QFT and represents unique challenges.
In this thesis we focus on the predictions for the \emph{hard scattering} process (we give a more precise definition of objects we are targeting in \cref{sec:hadcoll}),
which is where the fundamental structure of the SM is encoded to.
We obtain these predictions from the first principles through the perturbative expansion in the coupling constants of the SM, thus, directly linking the SM to measurements.
Naturally, the main source of theoretical uncertainties is then the truncation
of the perturbation series at some fixed order in the coupling constants.
And the systematic way to reduce this uncertainty is to include the higher orders of the expansion.

At the characteristic energy scales $\mu$ of the hard scattering at the LHC, the effective strong coupling constant $\alpha_s(\mu)$
is in the perturbative domain, but still is relatively large, compared to the couplings of the electro-weak (EW) interactions.
Therefore, the first most important corrections are generally expected to be from including higher orders in $\alpha_s(\mu)$.
In fact, for a considerable number of observables,
the leading order (LO) results provide only an order-of-magnitude estimates, and are not useful in precision phenomenology.
Furthermore, the LO computations, in essence, correspond to the classical limit of QFT, and do not reach into the quantum properties of the SM.

Computations beyond LO involve evaluation of loop amplitudes, and, in general,
%The former is the subject investigated in this thesis.
their complexity grows very rapidly with number of kinematical scales (such as Mandelstam invariants and masses)  and loop integrations involved.
With the current computational technology, at NLO order in $\alpha_s(\mu)$ the processes with at most seven particles in the final state
can be considered. One of the main results of this thesis is an example of one such computation:
the NLO QCD corrections to the production of the $W$-boson, decaying into a pair of leptons, in association with 
two bottom quarks and up to three additional light jets. We present this computation in \cref{chap:wbb_pheno},
where we also explain our motivation to consider it.


The technology for the computation of NLO QCD and EW corrections has seen an explosive development
in the recent decade, and became the standard of the field with many automated public tools available.
Typically, NLO QCD corrections provide first reliable theoretical predictions.
However, reaching the percent level accuracy of theoretical predictions requires (at least) NNLO QCD corrections.
Here, the state of the art is processes with only two particles in the final state.
One of the main bottlenecks of NNLO corrections with three particles in the final state is evaluation of two-loop five-point amplitudes.
The central result of this thesis, the first computation of all two-loop five-point amplitudes required for the production
of three jets at the hadron colliders, addresses this long-standing bottleneck. We present this computation in  \cref{chap:5parton}.

This bottleneck is caused by the fact,
that the standard techniques of evaluation of multi-loop amplitudes require too much computational resources,
when applied to five-point two-loop amplitudes in QCD.
Therefore, development and implementation of new algorithms was required.
In this thesis we employ the \emph{numerical unitarity} method, which
was originally formulated in the context of one-loop computations,
and has been recently extended for multi-loop applications.
We describe the numerical unitarity method in \cref{chap:numunitarity}.
One of its important components is a numerical treatment of dimensional regularization, which we use to regulate the divergences of loop integrals.
This is, perhaps, the main contribution to the development of the numerical unitarity method by the author of this thesis.
In particular, it is essential for evaluation of amplitudes with external fermions.
We discuss this in detail in \cref{chap:dshel}.

The computational algorithms, which we use in this thesis, are designed with primarily \emph{numerical} applications in mind.
The main result of the thesis, however, is the \emph{analytic expressions}.
We reconstruct them from samples of exact numerical evaluations of amplitudes over finite fields,
employing the functional interpolation techniques.
The application of these techniques in the field of perturbative computations in QFT is a rather new idea.
We, for the first time, systematically applied it to obtain a large number of phenomenologically-relevant amplitudes in an automated fashion. 
Exploiting the constraints on the analytic structure of the amplitudes, originating
from physical properties of the underlying theory, was essential to reduce the complexity of the reconstruction.

\subsubsection{Structure of this Thesis}

In \cref{chap:sm}, we provide some theoretical preliminaries required to understand the remaining 
content of the thesis.
We review the SM as a QFT, and  the definition of observables we are interested in.

The \cref{chap:stdtech} contains a summary of the standard techniques for computation of multi-loop amplitudes.
We also introduce some notation, which we use in the following chapters.

In \cref{chap:numunitarity}, we discuss in some detail the numerical unitarity method, which we employ for computation
of one- and two-loop amplitudes in this thesis.

in \cref{chap:dshel}, we describe our solution to the problem of numerical evaluation of multi-loop helicity amplitudes in dimensional regularization.

In \cref{chap:wbb_pheno}, we present the NLO QCD predictions for the \Wbbn{} production at the LHC.
We also provide an overview of the new automated implementation of the one-loop numerical unitarity method with massive particles in the one-loop matrix-element generator \BlackHat{}.

Finally, in \cref{chap:5parton} we present the main result of the thesis: the analytic form of all two-loop five-point amplitudes in QCD.
We provide some details of our implementation of the numerical unitarity method.
We give numerical benchmark evaluations of the amplitudes, 
and then describe the reconstruction of analytic expressions from numerical evaluations.
